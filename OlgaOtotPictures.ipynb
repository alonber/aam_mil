{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some setup so we can run all of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "from skimage.filters import sobel as edge\n",
    "# from IPython.display import display\n",
    "# from skimage.color import rgb2gray\n",
    "def load_image(path):\n",
    "    return np.uint8(np.array(Image.open(path)))\n",
    "\n",
    "def show_image(img_arg):\n",
    "    plt.imshow(img_arg, cmap = plt.cm.gray)\n",
    "    # imshow(img_arg)\n",
    "    # img_arg.show()\n",
    "    # display(Image.fromarray(img_arg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an image, print its dimensions, and display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = load_image(\"images/1.jpg\")\n",
    "print(f\"\\nImage's dimensions: {img.shape[0]} x {img.shape[1]} x {img.shape[2]}\")\n",
    "\n",
    "plt.figure(1, figsize=(10,5))\n",
    "show_image(img)\n",
    "plt.title('Original Image');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every image is a 3D array: M x N pixels, where each pixel is an array of 3 channels: R, G, B.\n",
    "\n",
    "In the following example, we display every channel separately, by zeroing out the other two channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = img.copy()\n",
    "r[:,:,1] = 0\n",
    "r[:,:,2] = 0\n",
    "\n",
    "g = img.copy()\n",
    "g[:,:,0] = 0\n",
    "g[:,:,2] = 0\n",
    "\n",
    "b = img.copy()\n",
    "b[:,:,0] = 0\n",
    "b[:,:,1] = 0\n",
    "\n",
    "plt.figure(2, figsize=(20,10));\n",
    "plt.subplot(1,3,1);\n",
    "show_image(r)\n",
    "plt.title('R');\n",
    "plt.subplot(1,3,2);\n",
    "show_image(g)\n",
    "plt.title('G');\n",
    "plt.subplot(1,3,3);\n",
    "show_image(b)\n",
    "plt.title('B');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to create a grayscale image from an RGB image.\n",
    "\n",
    "To create grayscale from RGB we would intuitively imply average the three channels.\n",
    "\n",
    "However, we should account for human perception (our eyes are more sensitive to some wavelengths than others).\n",
    "So we form a WEIGHTED average to account for this.\n",
    "Weâ€™re more sensitive to green than other colors, so green is weighted most heavily. \n",
    "The formula for luminosity is 0.21 R + 0.72 G + 0.07 B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_image(\"images/2.jpg\")\n",
    "def to_grayscale(img_arg):\n",
    "    return np.uint8(np.dot(img[...,:3], [0.21, 0.72, 0.07]))\n",
    "grayscale = to_grayscale(img)\n",
    "\n",
    "# Or we can just use an API that does this exact thing for us:\n",
    "# from skimage.color import rgb2gray\n",
    "# grayscale = rgb2gray(img)\n",
    "\n",
    "plt.figure(3, figsize=(20,10));\n",
    "plt.subplot(1,2,1);\n",
    "show_image(img)\n",
    "plt.title('RGB');\n",
    "plt.subplot(1,2,2);\n",
    "show_image(grayscale)\n",
    "plt.title('gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example shows what happens if we just take 200x200 pixels from an image, and display just them in the same frame size.\n",
    "\n",
    "Then, we take the small image and display it with different quantization levels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_image(\"images/3.jpg\")\n",
    "grayscale = to_grayscale(img)\n",
    "smallPic = grayscale[285:685,340:740]; # on smallPic - change the values to the \"important\" part of the image\n",
    "\n",
    "plt.figure(4, figsize=(20,10));\n",
    "plt.subplot(1,2,1);\n",
    "show_image(grayscale);\n",
    "plt.title('gray');\n",
    "plt.subplot(1,2,2);\n",
    "show_image(smallPic);\n",
    "plt.title('gray-\"zoom\" : display only 200x200 pixels')\n",
    "\n",
    "m = [1, 2, 4, 5, 8, 10, 20, 40, 50];\n",
    "rows, cols = smallPic.shape\n",
    "# assert rows == 200, f\"should create a 200x200 image in smallPic, instead got {rows} rows X {cols} columns\"\n",
    "assert rows == cols, f\"should create a square image in smallPic, instead got {rows} rows X {cols} columns\"\n",
    "\n",
    "quant = list()\n",
    "for j in m:\n",
    "    tmpPic = smallPic.copy();\n",
    "    for i in range(0, rows - 1, j):\n",
    "        for k in range(0, cols - 1, j):\n",
    "            surrounding = smallPic[i : i + j, k : k + j]\n",
    "            pixel_value = np.uint8(np.average(surrounding))\n",
    "            tmpPic[i : i + j, k : k + j] = pixel_value\n",
    "    quant.append(tmpPic)\n",
    "    \n",
    "plt.figure(5, figsize=(20, 20));\n",
    "for i, pic in enumerate(quant):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    show_image(pic)\n",
    "    j = m[i]\n",
    "    plt.title(f'avg {j} * {j} pixels --> ONE pixel');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we invert an image (turn dark areas to bright, and the other way around)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_image(\"images/4.jpg\")\n",
    "grayscale = to_grayscale(img)\n",
    "newImg = 255 - grayscale\n",
    "plt.figure(6, figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "show_image(grayscale)\n",
    "plt.subplot(1, 2, 2)\n",
    "show_image(newImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we are only interested in making edges (borders) stand out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_image(\"images/5.jpg\")\n",
    "img = to_grayscale(img)\n",
    "plt.figure(6, figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "show_image(img)\n",
    "plt.subplot(1, 2, 2)\n",
    "show_image(edge(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge detection is useful for computer vision. Think of autonomous vehicles that need to understand if they fit in some place!\n",
    "\n",
    "The specific way we calculated edges here is by going across rows and looking for big differences in values, and the same for columns. But this method has a downside: it fails to detect edges that are not vertical or horizontal. You can see that in the above image!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll see how quantization affects colors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = load_image(\"images/6.jpg\")\n",
    "plt.figure(6, figsize=(10, 11))\n",
    "plt.subplot(2, 2, 1)\n",
    "show_image(orig)\n",
    "plt.title('Original Image\\n(256^3 = 16M colors)')\n",
    "\n",
    "# to obtain 8 colors, we round each cell to the nearest quantization level out of:\n",
    "# 16, 48, 80, 112, 144, 176, 208, 240 (so 0..31 --> 16 , 32..63 --> 48, etc..)\n",
    "# generally, to obtain N colors, calculate X = 256 / N, then the levels are 0.5X, 1.5X, 2.5X, ...\n",
    "# then each pixel's quantization level is pixel floored to a multiple of X (0..31 --> 0), then added 0.5X.\n",
    "def quantize(image, num_levels):\n",
    "    x = 256 // num_levels\n",
    "    return np.uint8(np.floor_divide(image, x) * x + x / 2)\n",
    "\n",
    "img8 = quantize(orig, 8)\n",
    "img4 = quantize(orig, 4)\n",
    "img2 = quantize(orig, 2)\n",
    "        \n",
    "# plt.figure(7, figsize=(20, 10));\n",
    "plt.subplot(2,2,2);\n",
    "show_image(img8);\n",
    "plt.title('quantization to 8 colors / channel\\n(8^3 = 512 total colors)');\n",
    "plt.subplot(2,2,3);\n",
    "show_image(img4);\n",
    "plt.title('quantization to 4 colors / channel\\n(4^3 = 64 total colors)');\n",
    "plt.subplot(2,2,4);\n",
    "show_image(img2);       \n",
    "plt.title('quantization to 2 colors / channel\\n(2^3 = 8 total colors)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you guess how would quantization to 1 level per channel look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = quantize(orig, 1)\n",
    "plt.figure(8, figsize=(20, 3))\n",
    "show_image(img1)\n",
    "plt.title('quantization to 1 colors / channel (1^3 = 1 total color)');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
